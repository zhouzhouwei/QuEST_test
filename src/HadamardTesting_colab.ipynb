{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "4caa4f4650cb428bb42dcaa47cd0c592",
            "ba01c908dc0d4b2fa9dcd67d6bb1e442",
            "8f4f6f146b2c446ea374139b2c4b1218",
            "cdbb5e0390624d288f4715240dbe055e"
          ]
        },
        "id": "Xyg9_doibg6J",
        "outputId": "8f774081-9fe1-4aad-fadc-fd3d3fccdb2d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4caa4f4650cb428bb42dcaa47cd0c592",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba01c908dc0d4b2fa9dcd67d6bb1e442",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "summary.json:   0%|          | 0.00/1.83k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f4f6f146b2c446ea374139b2c4b1218",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdbb5e0390624d288f4715240dbe055e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "main.pt:   0%|          | 0.00/12.3G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'/nfs/scistore19/alistgrp/apanfero/QuEST/QuEST-800M-INT4'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "PATH = \"../QuEST-800M-INT4\"\n",
        "snapshot_download(repo_id=\"ISTA-DASLab/QuEST-800M-INT4\", local_dir=PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def compute_mse(grid):\n",
        "    \"\"\"\n",
        "    Compute the Mean Squared Error (MSE) for a given scaling parameter 'a' and number of quantization levels 'N'.\n",
        "    \"\"\"\n",
        "    print(f\"quant center: {grid}\")\n",
        "    q = [-np.inf] + [(grid[i] + grid[i+1]) / 2 for i in range(len(grid) - 1)] + [np.inf]  # Quantization boundaries\n",
        "    print(f\"q values: {q}\")\n",
        "    MSE = 0.0\n",
        "    for i in range(len(grid)):\n",
        "        left = q[i]\n",
        "        right = q[i + 1]\n",
        "        center = grid[i]\n",
        "\n",
        "        # Probability of the interval\n",
        "        P_i = norm.cdf(right) - norm.cdf(left)\n",
        "\n",
        "        # First and second moments over the interval\n",
        "        M1_i = norm.expect(lambda t: t, loc=0, scale=1, lb=left, ub=right)\n",
        "        M2_i = norm.expect(lambda t: t**2, loc=0, scale=1, lb=left, ub=right)\n",
        "\n",
        "        # MSE for the i-th interval\n",
        "        E_i = M2_i - 2 * center * M1_i + center**2 * P_i\n",
        "        MSE += E_i\n",
        "\n",
        "    # Total MSE\n",
        "    return MSE\n",
        "\n",
        "def get_uniform_grid(a, N):\n",
        "    return np.linspace(-a, a, N)\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "from tqdm.auto import tqdm\n",
        "bits = 4\n",
        "N = 2**bits  # You can change this value as needed\n",
        "\n",
        "# Objective function for minimization\n",
        "def objective(a):\n",
        "  return compute_mse(get_uniform_grid(a[0], N))\n",
        "\n",
        "# Initial guess for 'a'\n",
        "a0 = [2.0]\n",
        "\n",
        "# Bounds for 'a' to ensure it's positive\n",
        "bounds = [(0.1, 10.0)]\n",
        "\n",
        "# Minimize the MSE\n",
        "result = minimize(objective, a0, bounds=bounds, method='L-BFGS-B')\n",
        "\n",
        "# Optimal scaling parameter and corresponding MSE\n",
        "optimal_a = result.x[0]\n",
        "minimum_mse = result.fun\n",
        "\n",
        "print(f\"bits: {bits}: optimal scaling parameter (a): {optimal_a}, Minimum MSE: {minimum_mse}\")"
      ],
      "metadata": {
        "id": "D7URH4GSirac",
        "outputId": "a6d42289-97d5-4540-cdf6-ee1d27a3fb1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quant center: [-2.         -1.73333333 -1.46666667 -1.2        -0.93333333 -0.66666667\n",
            " -0.4        -0.13333333  0.13333333  0.4         0.66666667  0.93333333\n",
            "  1.2         1.46666667  1.73333333  2.        ]\n",
            "q values: [-inf, np.float64(-1.8666666666666667), np.float64(-1.6), np.float64(-1.3333333333333335), np.float64(-1.0666666666666667), np.float64(-0.8), np.float64(-0.5333333333333333), np.float64(-0.2666666666666666), np.float64(0.0), np.float64(0.2666666666666666), np.float64(0.5333333333333332), np.float64(0.7999999999999998), np.float64(1.0666666666666667), np.float64(1.3333333333333335), np.float64(1.6), np.float64(1.8666666666666667), inf]\n",
            "quant center: [-2.00000001 -1.73333334 -1.46666667 -1.20000001 -0.93333334 -0.66666667\n",
            " -0.4        -0.13333333  0.13333333  0.4         0.66666667  0.93333334\n",
            "  1.20000001  1.46666667  1.73333334  2.00000001]\n",
            "q values: [-inf, np.float64(-1.866666676), np.float64(-1.6000000079999999), np.float64(-1.3333333399999998), np.float64(-1.066666672), np.float64(-0.8000000039999999), np.float64(-0.533333336), np.float64(-0.26666666800000005), np.float64(0.0), np.float64(0.26666666800000005), np.float64(0.5333333360000001), np.float64(0.8000000040000002), np.float64(1.066666672), np.float64(1.3333333399999998), np.float64(1.6000000079999999), np.float64(1.866666676), inf]\n",
            "quant center: [-2.02766533 -1.75730995 -1.48695457 -1.2165992  -0.94624382 -0.67588844\n",
            " -0.40553307 -0.13517769  0.13517769  0.40553307  0.67588844  0.94624382\n",
            "  1.2165992   1.48695457  1.75730995  2.02766533]\n",
            "q values: [-inf, np.float64(-1.8924876376943014), np.float64(-1.6221322608808295), np.float64(-1.351776884067358), np.float64(-1.0814215072538866), np.float64(-0.8110661304404149), np.float64(-0.5407107536269433), np.float64(-0.27035537681347177), np.float64(-1.1102230246251565e-16), np.float64(0.27035537681347144), np.float64(0.5407107536269431), np.float64(0.8110661304404148), np.float64(1.0814215072538862), np.float64(1.3517768840673579), np.float64(1.6221322608808295), np.float64(1.8924876376943012), inf]\n",
            "quant center: [-2.02766534 -1.75730996 -1.48695458 -1.2165992  -0.94624382 -0.67588845\n",
            " -0.40553307 -0.13517769  0.13517769  0.40553307  0.67588845  0.94624382\n",
            "  1.2165992   1.48695458  1.75730996  2.02766534]\n",
            "q values: [-inf, np.float64(-1.8924876470276346), np.float64(-1.6221322688808297), np.float64(-1.3517768907340248), np.float64(-1.0814215125872197), np.float64(-0.8110661344404149), np.float64(-0.5407107562936099), np.float64(-0.2703553781468049), np.float64(0.0), np.float64(0.2703553781468049), np.float64(0.5407107562936098), np.float64(0.8110661344404146), np.float64(1.0814215125872197), np.float64(1.3517768907340248), np.float64(1.6221322688808297), np.float64(1.8924876470276346), inf]\n",
            "quant center: [-2.30442351 -1.99716704 -1.68991057 -1.3826541  -1.07539764 -0.76814117\n",
            " -0.4608847  -0.15362823  0.15362823  0.4608847   0.76814117  1.07539764\n",
            "  1.3826541   1.68991057  1.99716704  2.30442351]\n",
            "q values: [-inf, np.float64(-2.150795271657112), np.float64(-1.8435388042775243), np.float64(-1.536282336897937), np.float64(-1.2290258695183498), np.float64(-0.9217694021387622), np.float64(-0.6145129347591749), np.float64(-0.30725646737958745), np.float64(0.0), np.float64(0.30725646737958723), np.float64(0.6145129347591747), np.float64(0.9217694021387621), np.float64(1.2290258695183494), np.float64(1.5362823368979368), np.float64(1.8435388042775245), np.float64(2.150795271657112), inf]\n",
            "quant center: [-2.30442352 -1.99716705 -1.68991058 -1.38265411 -1.07539764 -0.76814117\n",
            " -0.4608847  -0.15362823  0.15362823  0.4608847   0.76814117  1.07539764\n",
            "  1.38265411  1.68991058  1.99716705  2.30442352]\n",
            "q values: [-inf, np.float64(-2.150795280990445), np.float64(-1.8435388122775245), np.float64(-1.5362823435646038), np.float64(-1.229025874851683), np.float64(-0.9217694061387622), np.float64(-0.6145129374258415), np.float64(-0.30725646871292067), np.float64(0.0), np.float64(0.30725646871292067), np.float64(0.6145129374258413), np.float64(0.921769406138762), np.float64(1.229025874851683), np.float64(1.5362823435646038), np.float64(1.8435388122775245), np.float64(2.150795280990445), inf]\n",
            "quant center: [-2.41833852 -2.09589339 -1.77344825 -1.45100311 -1.12855798 -0.80611284\n",
            " -0.4836677  -0.16122257  0.16122257  0.4836677   0.80611284  1.12855798\n",
            "  1.45100311  1.77344825  2.09589339  2.41833852]\n",
            "q values: [-inf, np.float64(-2.25711595499175), np.float64(-1.934670818564357), np.float64(-1.6122256821369643), np.float64(-1.2897805457095712), np.float64(-0.9673354092821785), np.float64(-0.6448902728547856), np.float64(-0.3224451364273928), np.float64(0.0), np.float64(0.32244513642739303), np.float64(0.6448902728547858), np.float64(0.9673354092821786), np.float64(1.2897805457095717), np.float64(1.6122256821369647), np.float64(1.9346708185643573), np.float64(2.25711595499175), inf]\n",
            "quant center: [-2.41833853 -2.0958934  -1.77344826 -1.45100312 -1.12855798 -0.80611284\n",
            " -0.48366771 -0.16122257  0.16122257  0.48366771  0.80611284  1.12855798\n",
            "  1.45100312  1.77344826  2.0958934   2.41833853]\n",
            "q values: [-inf, np.float64(-2.2571159643250835), np.float64(-1.934670826564357), np.float64(-1.6122256888036308), np.float64(-1.2897805510429046), np.float64(-0.9673354132821784), np.float64(-0.6448902755214523), np.float64(-0.32244513776072603), np.float64(2.220446049250313e-16), np.float64(0.32244513776072625), np.float64(0.6448902755214525), np.float64(0.9673354132821788), np.float64(1.2897805510429048), np.float64(1.612225688803631), np.float64(1.9346708265643575), np.float64(2.2571159643250835), inf]\n",
            "quant center: [-2.49163555 -2.15941748 -1.8271994  -1.49498133 -1.16276326 -0.83054518\n",
            " -0.49832711 -0.16610904  0.16610904  0.49832711  0.83054518  1.16276326\n",
            "  1.49498133  1.8271994   2.15941748  2.49163555]\n",
            "q values: [-inf, np.float64(-2.32552651162275), np.float64(-1.9933084385337856), np.float64(-1.6610903654448212), np.float64(-1.3288722923558571), np.float64(-0.9966542192668928), np.float64(-0.6644361461779286), np.float64(-0.33221807308896434), np.float64(0.0), np.float64(0.33221807308896434), np.float64(0.6644361461779287), np.float64(0.996654219266893), np.float64(1.3288722923558571), np.float64(1.6610903654448212), np.float64(1.9933084385337856), np.float64(2.32552651162275), inf]\n",
            "quant center: [-2.49163556 -2.15941748 -1.82719941 -1.49498133 -1.16276326 -0.83054519\n",
            " -0.49832711 -0.16610904  0.16610904  0.49832711  0.83054519  1.16276326\n",
            "  1.49498133  1.82719941  2.15941748  2.49163556]\n",
            "q values: [-inf, np.float64(-2.325526520956083), np.float64(-1.9933084465337856), np.float64(-1.661090372111488), np.float64(-1.3288722976891902), np.float64(-0.9966542232668928), np.float64(-0.6644361488445951), np.float64(-0.33221807442229756), np.float64(0.0), np.float64(0.3322180744222978), np.float64(0.6644361488445953), np.float64(0.9966542232668929), np.float64(1.3288722976891907), np.float64(1.6610903721114885), np.float64(1.9933084465337858), np.float64(2.325526520956083), inf]\n",
            "quant center: [-2.51141459 -2.17655931 -1.84170403 -1.50684875 -1.17199348 -0.8371382\n",
            " -0.50228292 -0.16742764  0.16742764  0.50228292  0.8371382   1.17199348\n",
            "  1.50684875  1.84170403  2.17655931  2.51141459]\n",
            "q values: [-inf, np.float64(-2.3439869502917356), np.float64(-2.0091316716786305), np.float64(-1.6742763930655253), np.float64(-1.3394211144524204), np.float64(-1.0045658358393152), np.float64(-0.6697105572262102), np.float64(-0.33485527861310516), np.float64(0.0), np.float64(0.33485527861310516), np.float64(0.6697105572262103), np.float64(1.0045658358393155), np.float64(1.3394211144524204), np.float64(1.6742763930655253), np.float64(2.0091316716786305), np.float64(2.3439869502917356), inf]\n",
            "quant center: [-2.5114146  -2.17655932 -1.84170404 -1.50684876 -1.17199348 -0.8371382\n",
            " -0.50228292 -0.16742764  0.16742764  0.50228292  0.8371382   1.17199348\n",
            "  1.50684876  1.84170404  2.17655932  2.5114146 ]\n",
            "q values: [-inf, np.float64(-2.343986959625069), np.float64(-2.0091316796786307), np.float64(-1.674276399732192), np.float64(-1.3394211197857535), np.float64(-1.0045658398393154), np.float64(-0.6697105598928768), np.float64(-0.3348552799464384), np.float64(0.0), np.float64(0.3348552799464386), np.float64(0.669710559892877), np.float64(1.0045658398393154), np.float64(1.339421119785754), np.float64(1.6742763997321926), np.float64(2.0091316796786307), np.float64(2.343986959625069), inf]\n",
            "quant center: [-2.51393314 -2.17874205 -1.84355097 -1.50835988 -1.1731688  -0.83797771\n",
            " -0.50278663 -0.16759554  0.16759554  0.50278663  0.83797771  1.1731688\n",
            "  1.50835988  1.84355097  2.17874205  2.51393314]\n",
            "q values: [-inf, np.float64(-2.3463375972126395), np.float64(-2.0111465118965484), np.float64(-1.675955426580457), np.float64(-1.3407643412643657), np.float64(-1.0055732559482742), np.float64(-0.6703821706321829), np.float64(-0.33519108531609154), np.float64(-2.220446049250313e-16), np.float64(0.3351910853160913), np.float64(0.6703821706321826), np.float64(1.005573255948274), np.float64(1.3407643412643655), np.float64(1.6759554265804568), np.float64(2.011146511896548), np.float64(2.3463375972126395), inf]\n",
            "quant center: [-2.51393315 -2.17874206 -1.84355098 -1.50835989 -1.1731688  -0.83797772\n",
            " -0.50278663 -0.16759554  0.16759554  0.50278663  0.83797772  1.1731688\n",
            "  1.50835989  1.84355098  2.17874206  2.51393315]\n",
            "q values: [-inf, np.float64(-2.346337606545973), np.float64(-2.011146519896548), np.float64(-1.6759554332471236), np.float64(-1.340764346597699), np.float64(-1.005573259948274), np.float64(-0.6703821732988495), np.float64(-0.33519108664942476), np.float64(0.0), np.float64(0.33519108664942454), np.float64(0.6703821732988493), np.float64(1.005573259948274), np.float64(1.3407643465976986), np.float64(1.6759554332471231), np.float64(2.011146519896548), np.float64(2.346337606545973), inf]\n",
            "bits: 4: optimal scaling parameter (a): 2.5139331398706855, Minimum MSE: 0.011542884499013197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fp4_grid(a:float=1):\n",
        "    zeros = [+0, -0]\n",
        "    normal = [sign * (1+m)/2 * 2**(e-1) for sign in [1, -1] for e in range(1,4) for m in range(1,3)]\n",
        "    subnormal = [sign * (0+m) * 2**(-1) for m in range(1,2) for sign in [1, -1]]\n",
        "    return a * np.array(sorted(zeros + normal + subnormal))\n",
        "\n",
        "fp4_grid = get_fp4_grid()\n",
        "print(fp4_grid)\n",
        "\n",
        "# Objective function for minimization\n",
        "def objective(a):\n",
        "    return compute_mse(get_fp4_grid(a[0]))\n",
        "\n",
        "# Initial guess for 'a'\n",
        "a0 = [1.0]\n",
        "\n",
        "# Bounds for 'a' to ensure it's positive\n",
        "bounds = [(0.1, 10.0)]\n",
        "\n",
        "# Minimize the MSE\n",
        "result = minimize(objective, a0, bounds=bounds, method='L-BFGS-B')\n",
        "\n",
        "# Optimal scaling parameter and corresponding MSE\n",
        "optimal_a = result.x[0]\n",
        "minimum_mse = result.fun\n",
        "\n",
        "print(f\"Optimal scaling parameter (a): {optimal_a}\")\n",
        "print(f\"Minimum MSE: {minimum_mse}\")"
      ],
      "metadata": {
        "id": "OjbBzcYIT_dW",
        "outputId": "bad1266f-3d74-4867-bf70-a395a8bef29c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-6.  -4.  -3.  -2.  -1.5 -1.  -0.5  0.   0.   0.5  1.   1.5  2.   3.\n",
            "  4.   6. ]\n",
            "quant center: [-6.  -4.  -3.  -2.  -1.5 -1.  -0.5  0.   0.   0.5  1.   1.5  2.   3.\n",
            "  4.   6. ]\n",
            "q values: [-inf, np.float64(-5.0), np.float64(-3.5), np.float64(-2.5), np.float64(-1.75), np.float64(-1.25), np.float64(-0.75), np.float64(-0.25), np.float64(0.0), np.float64(0.25), np.float64(0.75), np.float64(1.25), np.float64(1.75), np.float64(2.5), np.float64(3.5), np.float64(5.0), inf]\n",
            "quant center: [-6.00000006 -4.00000004 -3.00000003 -2.00000002 -1.50000001 -1.00000001\n",
            " -0.5         0.          0.          0.5         1.00000001  1.50000001\n",
            "  2.00000002  3.00000003  4.00000004  6.00000006]\n",
            "q values: [-inf, np.float64(-5.00000005), np.float64(-3.500000035), np.float64(-2.500000025), np.float64(-1.7500000175), np.float64(-1.2500000125), np.float64(-0.7500000075), np.float64(-0.2500000025), np.float64(0.0), np.float64(0.2500000025), np.float64(0.7500000075), np.float64(1.2500000125), np.float64(1.7500000175), np.float64(2.500000025), np.float64(3.500000035), np.float64(5.00000005), inf]\n",
            "quant center: [-5.79906772 -3.86604515 -2.89953386 -1.93302257 -1.44976693 -0.96651129\n",
            " -0.48325564  0.          0.          0.48325564  0.96651129  1.44976693\n",
            "  1.93302257  2.89953386  3.86604515  5.79906772]\n",
            "q values: [-inf, np.float64(-4.83255643649471), np.float64(-3.382789505546297), np.float64(-2.416278218247355), np.float64(-1.6913947527731485), np.float64(-1.2081391091236775), np.float64(-0.7248834654742065), np.float64(-0.2416278218247355), np.float64(0.0), np.float64(0.2416278218247355), np.float64(0.7248834654742065), np.float64(1.2081391091236775), np.float64(1.6913947527731485), np.float64(2.416278218247355), np.float64(3.382789505546297), np.float64(4.83255643649471), inf]\n",
            "quant center: [-5.79906778 -3.86604519 -2.89953389 -1.93302259 -1.44976695 -0.9665113\n",
            " -0.48325565  0.          0.          0.48325565  0.9665113   1.44976695\n",
            "  1.93302259  2.89953389  3.86604519  5.79906778]\n",
            "q values: [-inf, np.float64(-4.83255648649471), np.float64(-3.3827895405462973), np.float64(-2.416278243247355), np.float64(-1.6913947702731487), np.float64(-1.2081391216236774), np.float64(-0.7248834729742065), np.float64(-0.2416278243247355), np.float64(0.0), np.float64(0.2416278243247355), np.float64(0.7248834729742065), np.float64(1.2081391216236774), np.float64(1.6913947702731487), np.float64(2.416278243247355), np.float64(3.3827895405462973), np.float64(4.83255648649471), inf]\n",
            "quant center: [-2.11501139 -1.41000759 -1.0575057  -0.7050038  -0.52875285 -0.3525019\n",
            " -0.17625095  0.          0.          0.17625095  0.3525019   0.52875285\n",
            "  0.7050038   1.0575057   1.41000759  2.11501139]\n",
            "q values: [-inf, np.float64(-1.762509493162247), np.float64(-1.2337566452135729), np.float64(-0.8812547465811235), np.float64(-0.6168783226067864), np.float64(-0.44062737329056173), np.float64(-0.264376423974337), np.float64(-0.08812547465811235), np.float64(0.0), np.float64(0.08812547465811235), np.float64(0.264376423974337), np.float64(0.44062737329056173), np.float64(0.6168783226067864), np.float64(0.8812547465811235), np.float64(1.2337566452135729), np.float64(1.762509493162247), inf]\n",
            "quant center: [-2.11501145 -1.41000763 -1.05750573 -0.70500382 -0.52875286 -0.35250191\n",
            " -0.17625095  0.          0.          0.17625095  0.35250191  0.52875286\n",
            "  0.70500382  1.05750573  1.41000763  2.11501145]\n",
            "q values: [-inf, np.float64(-1.7625095431622468), np.float64(-1.2337566802135729), np.float64(-0.8812547715811234), np.float64(-0.6168783401067864), np.float64(-0.4406273857905617), np.float64(-0.26437643147433704), np.float64(-0.08812547715811235), np.float64(0.0), np.float64(0.08812547715811235), np.float64(0.26437643147433704), np.float64(0.4406273857905617), np.float64(0.6168783401067864), np.float64(0.8812547715811234), np.float64(1.2337566802135729), np.float64(1.7625095431622468), inf]\n",
            "quant center: [-5.0305282  -3.35368546 -2.5152641  -1.67684273 -1.25763205 -0.83842137\n",
            " -0.41921068  0.          0.          0.41921068  0.83842137  1.25763205\n",
            "  1.67684273  2.5152641   3.35368546  5.0305282 ]\n",
            "q values: [-inf, np.float64(-4.192106830048925), np.float64(-2.934474781034247), np.float64(-2.0960534150244623), np.float64(-1.4672373905171234), np.float64(-1.0480267075122311), np.float64(-0.6288160245073386), np.float64(-0.20960534150244622), np.float64(0.0), np.float64(0.20960534150244622), np.float64(0.6288160245073386), np.float64(1.0480267075122311), np.float64(1.4672373905171234), np.float64(2.0960534150244623), np.float64(2.934474781034247), np.float64(4.192106830048925), inf]\n",
            "quant center: [-5.03052826 -3.3536855  -2.51526413 -1.67684275 -1.25763206 -0.83842138\n",
            " -0.41921069  0.          0.          0.41921069  0.83842138  1.25763206\n",
            "  1.67684275  2.51526413  3.3536855   5.03052826]\n",
            "q values: [-inf, np.float64(-4.192106880048925), np.float64(-2.934474816034247), np.float64(-2.0960534400244626), np.float64(-1.4672374080171235), np.float64(-1.0480267200122313), np.float64(-0.6288160320073387), np.float64(-0.20960534400244624), np.float64(0.0), np.float64(0.20960534400244624), np.float64(0.6288160320073387), np.float64(1.0480267200122313), np.float64(1.4672374080171235), np.float64(2.0960534400244626), np.float64(2.934474816034247), np.float64(4.192106880048925), inf]\n",
            "quant center: [-1.6288365  -1.085891   -0.81441825 -0.5429455  -0.40720913 -0.27147275\n",
            " -0.13573638  0.          0.          0.13573638  0.27147275  0.40720913\n",
            "  0.5429455   0.81441825  1.085891    1.6288365 ]\n",
            "q values: [-inf, np.float64(-1.3573637523747042), np.float64(-0.950154626662293), np.float64(-0.6786818761873521), np.float64(-0.4750773133311465), np.float64(-0.33934093809367605), np.float64(-0.20360456285620565), np.float64(-0.06786818761873521), np.float64(0.0), np.float64(0.06786818761873521), np.float64(0.20360456285620565), np.float64(0.33934093809367605), np.float64(0.4750773133311465), np.float64(0.6786818761873521), np.float64(0.950154626662293), np.float64(1.3573637523747042), inf]\n",
            "quant center: [-1.62883656 -1.08589104 -0.81441828 -0.54294552 -0.40720914 -0.27147276\n",
            " -0.13573638  0.          0.          0.13573638  0.27147276  0.40720914\n",
            "  0.54294552  0.81441828  1.08589104  1.62883656]\n",
            "q values: [-inf, np.float64(-1.3573638023747043), np.float64(-0.9501546616622929), np.float64(-0.6786819011873522), np.float64(-0.47507733083114645), np.float64(-0.3393409505936761), np.float64(-0.20360457035620563), np.float64(-0.06786819011873521), np.float64(0.0), np.float64(0.06786819011873521), np.float64(0.20360457035620563), np.float64(0.3393409505936761), np.float64(0.47507733083114645), np.float64(0.6786819011873522), np.float64(0.9501546616622929), np.float64(1.3573638023747043), inf]\n",
            "quant center: [-3.66945952 -2.44630635 -1.83472976 -1.22315317 -0.91736488 -0.61157659\n",
            " -0.30578829  0.          0.          0.30578829  0.61157659  0.91736488\n",
            "  1.22315317  1.83472976  2.44630635  3.66945952]\n",
            "q values: [-inf, np.float64(-3.0578829322383543), np.float64(-2.140518052566848), np.float64(-1.5289414661191771), np.float64(-1.070259026283424), np.float64(-0.7644707330595886), np.float64(-0.4586824398357532), np.float64(-0.15289414661191772), np.float64(0.0), np.float64(0.15289414661191772), np.float64(0.4586824398357532), np.float64(0.7644707330595886), np.float64(1.070259026283424), np.float64(1.5289414661191771), np.float64(2.140518052566848), np.float64(3.0578829322383543), inf]\n",
            "quant center: [-3.66945958 -2.44630639 -1.83472979 -1.22315319 -0.91736489 -0.6115766\n",
            " -0.3057883   0.          0.          0.3057883   0.6115766   0.91736489\n",
            "  1.22315319  1.83472979  2.44630639  3.66945958]\n",
            "q values: [-inf, np.float64(-3.057882982238355), np.float64(-2.140518087566848), np.float64(-1.5289414911191774), np.float64(-1.070259043783424), np.float64(-0.7644707455595887), np.float64(-0.4586824473357532), np.float64(-0.15289414911191773), np.float64(0.0), np.float64(0.15289414911191773), np.float64(0.4586824473357532), np.float64(0.7644707455595887), np.float64(1.070259043783424), np.float64(1.5289414911191774), np.float64(2.140518087566848), np.float64(3.057882982238355), inf]\n",
            "quant center: [-1.99285367 -1.32856911 -0.99642684 -0.66428456 -0.49821342 -0.33214228\n",
            " -0.16607114  0.          0.          0.16607114  0.33214228  0.49821342\n",
            "  0.66428456  0.99642684  1.32856911  1.99285367]\n",
            "q values: [-inf, np.float64(-1.6607113930054394), np.float64(-1.1624979751038076), np.float64(-0.8303556965027197), np.float64(-0.5812489875519038), np.float64(-0.41517784825135984), np.float64(-0.24910670895081588), np.float64(-0.08303556965027196), np.float64(0.0), np.float64(0.08303556965027196), np.float64(0.24910670895081588), np.float64(0.41517784825135984), np.float64(0.5812489875519038), np.float64(0.8303556965027197), np.float64(1.1624979751038076), np.float64(1.6607113930054394), inf]\n",
            "quant center: [-1.99285373 -1.32856915 -0.99642687 -0.66428458 -0.49821343 -0.33214229\n",
            " -0.16607114  0.          0.          0.16607114  0.33214229  0.49821343\n",
            "  0.66428458  0.99642687  1.32856915  1.99285373]\n",
            "q values: [-inf, np.float64(-1.6607114430054393), np.float64(-1.1624980101038074), np.float64(-0.8303557215027196), np.float64(-0.5812490050519037), np.float64(-0.4151778607513598), np.float64(-0.2491067164508159), np.float64(-0.08303557215027196), np.float64(0.0), np.float64(0.08303557215027196), np.float64(0.2491067164508159), np.float64(0.4151778607513598), np.float64(0.5812490050519037), np.float64(0.8303557215027196), np.float64(1.1624980101038074), np.float64(1.6607114430054393), inf]\n",
            "quant center: [-3.0898358  -2.05989053 -1.5449179  -1.02994527 -0.77245895 -0.51497263\n",
            " -0.25748632  0.          0.          0.25748632  0.51497263  0.77245895\n",
            "  1.02994527  1.5449179   2.05989053  3.0898358 ]\n",
            "q values: [-inf, np.float64(-2.5748631647264197), np.float64(-1.8024042153084938), np.float64(-1.2874315823632099), np.float64(-0.9012021076542469), np.float64(-0.6437157911816049), np.float64(-0.38622947470896296), np.float64(-0.128743158236321), np.float64(0.0), np.float64(0.128743158236321), np.float64(0.38622947470896296), np.float64(0.6437157911816049), np.float64(0.9012021076542469), np.float64(1.2874315823632099), np.float64(1.8024042153084938), np.float64(2.5748631647264197), inf]\n",
            "quant center: [-3.08983586 -2.05989057 -1.54491793 -1.02994529 -0.77245896 -0.51497264\n",
            " -0.25748632  0.          0.          0.25748632  0.51497264  0.77245896\n",
            "  1.02994529  1.54491793  2.05989057  3.08983586]\n",
            "q values: [-inf, np.float64(-2.5748632147264203), np.float64(-1.802404250308494), np.float64(-1.2874316073632102), np.float64(-0.901202125154247), np.float64(-0.6437158036816051), np.float64(-0.386229482208963), np.float64(-0.128743160736321), np.float64(0.0), np.float64(0.128743160736321), np.float64(0.386229482208963), np.float64(0.6437158036816051), np.float64(0.901202125154247), np.float64(1.2874316073632102), np.float64(1.802404250308494), np.float64(2.5748632147264203), inf]\n",
            "quant center: [-2.78078281 -1.8538552  -1.3903914  -0.9269276  -0.6951957  -0.4634638\n",
            " -0.2317319   0.          0.          0.2317319   0.4634638   0.6951957\n",
            "  0.9269276   1.3903914   1.8538552   2.78078281]\n",
            "q values: [-inf, np.float64(-2.3173190049589563), np.float64(-1.6221233034712692), np.float64(-1.1586595024794781), np.float64(-0.8110616517356346), np.float64(-0.5793297512397391), np.float64(-0.3475978507438434), np.float64(-0.11586595024794781), np.float64(0.0), np.float64(0.11586595024794781), np.float64(0.3475978507438434), np.float64(0.5793297512397391), np.float64(0.8110616517356346), np.float64(1.1586595024794781), np.float64(1.6221233034712692), np.float64(2.3173190049589563), inf]\n",
            "quant center: [-2.78078287 -1.85385524 -1.39039143 -0.92692762 -0.69519572 -0.46346381\n",
            " -0.23173191  0.          0.          0.23173191  0.46346381  0.69519572\n",
            "  0.92692762  1.39039143  1.85385524  2.78078287]\n",
            "q values: [-inf, np.float64(-2.317319054958956), np.float64(-1.6221233384712694), np.float64(-1.158659527479478), np.float64(-0.8110616692356347), np.float64(-0.579329763739739), np.float64(-0.3475978582438434), np.float64(-0.11586595274794781), np.float64(0.0), np.float64(0.11586595274794781), np.float64(0.3475978582438434), np.float64(0.579329763739739), np.float64(0.8110616692356347), np.float64(1.158659527479478), np.float64(1.6221233384712694), np.float64(2.317319054958956), inf]\n",
            "quant center: [-2.95393167 -1.96928778 -1.47696584 -0.98464389 -0.73848292 -0.49232195\n",
            " -0.24616097  0.          0.          0.24616097  0.49232195  0.73848292\n",
            "  0.98464389  1.47696584  1.96928778  2.95393167]\n",
            "q values: [-inf, np.float64(-2.46160972864107), np.float64(-1.723126810048749), np.float64(-1.230804864320535), np.float64(-0.8615634050243745), np.float64(-0.6154024321602675), np.float64(-0.3692414592961605), np.float64(-0.12308048643205349), np.float64(0.0), np.float64(0.12308048643205349), np.float64(0.3692414592961605), np.float64(0.6154024321602675), np.float64(0.8615634050243745), np.float64(1.230804864320535), np.float64(1.723126810048749), np.float64(2.46160972864107), inf]\n",
            "quant center: [-2.95393173 -1.96928782 -1.47696587 -0.98464391 -0.73848293 -0.49232196\n",
            " -0.24616098  0.          0.          0.24616098  0.49232196  0.73848293\n",
            "  0.98464391  1.47696587  1.96928782  2.95393173]\n",
            "q values: [-inf, np.float64(-2.46160977864107), np.float64(-1.723126845048749), np.float64(-1.230804889320535), np.float64(-0.8615634225243745), np.float64(-0.6154024446602675), np.float64(-0.3692414667961605), np.float64(-0.12308048893205349), np.float64(0.0), np.float64(0.12308048893205349), np.float64(0.3692414667961605), np.float64(0.6154024446602675), np.float64(0.8615634225243745), np.float64(1.230804889320535), np.float64(1.723126845048749), np.float64(2.46160977864107), inf]\n",
            "quant center: [-2.91532694 -1.94355129 -1.45766347 -0.97177565 -0.72883173 -0.48588782\n",
            " -0.24294391  0.          0.          0.24294391  0.48588782  0.72883173\n",
            "  0.97177565  1.45766347  1.94355129  2.91532694]\n",
            "q values: [-inf, np.float64(-2.4294391153368493), np.float64(-1.7006073807357944), np.float64(-1.2147195576684247), np.float64(-0.8503036903678972), np.float64(-0.6073597788342123), np.float64(-0.3644158673005274), np.float64(-0.12147195576684246), np.float64(0.0), np.float64(0.12147195576684246), np.float64(0.3644158673005274), np.float64(0.6073597788342123), np.float64(0.8503036903678972), np.float64(1.2147195576684247), np.float64(1.7006073807357944), np.float64(2.4294391153368493), inf]\n",
            "quant center: [-2.915327   -1.94355133 -1.4576635  -0.97177567 -0.72883175 -0.48588783\n",
            " -0.24294392  0.          0.          0.24294392  0.48588783  0.72883175\n",
            "  0.97177567  1.4576635   1.94355133  2.915327  ]\n",
            "q values: [-inf, np.float64(-2.4294391653368494), np.float64(-1.7006074157357944), np.float64(-1.2147195826684247), np.float64(-0.8503037078678972), np.float64(-0.6073597913342124), np.float64(-0.3644158748005274), np.float64(-0.12147195826684246), np.float64(0.0), np.float64(0.12147195826684246), np.float64(0.3644158748005274), np.float64(0.6073597913342124), np.float64(0.8503037078678972), np.float64(1.2147195826684247), np.float64(1.7006074157357944), np.float64(2.4294391653368494), inf]\n",
            "quant center: [-2.92277761 -1.94851841 -1.4613888  -0.9742592  -0.7306944  -0.4871296\n",
            " -0.2435648   0.          0.          0.2435648   0.4871296   0.7306944\n",
            "  0.9742592   1.4613888   1.94851841  2.92277761]\n",
            "q values: [-inf, np.float64(-2.4356480066255317), np.float64(-1.7049536046378724), np.float64(-1.2178240033127659), np.float64(-0.8524768023189362), np.float64(-0.6089120016563829), np.float64(-0.3653472009938298), np.float64(-0.12178240033127659), np.float64(0.0), np.float64(0.12178240033127659), np.float64(0.3653472009938298), np.float64(0.6089120016563829), np.float64(0.8524768023189362), np.float64(1.2178240033127659), np.float64(1.7049536046378724), np.float64(2.4356480066255317), inf]\n",
            "quant center: [-2.92277767 -1.94851845 -1.46138883 -0.97425922 -0.73069442 -0.48712961\n",
            " -0.24356481  0.          0.          0.24356481  0.48712961  0.73069442\n",
            "  0.97425922  1.46138883  1.94851845  2.92277767]\n",
            "q values: [-inf, np.float64(-2.4356480566255314), np.float64(-1.7049536396378722), np.float64(-1.2178240283127657), np.float64(-0.8524768198189361), np.float64(-0.6089120141563829), np.float64(-0.36534720849382973), np.float64(-0.12178240283127659), np.float64(0.0), np.float64(0.12178240283127659), np.float64(0.36534720849382973), np.float64(0.6089120141563829), np.float64(0.8524768198189361), np.float64(1.2178240283127657), np.float64(1.7049536396378722), np.float64(2.4356480566255314), inf]\n",
            "quant center: [-2.92247751 -1.94831834 -1.46123876 -0.97415917 -0.73061938 -0.48707959\n",
            " -0.24353979  0.          0.          0.24353979  0.48707959  0.73061938\n",
            "  0.97415917  1.46123876  1.94831834  2.92247751]\n",
            "q values: [-inf, np.float64(-2.4353979252941267), np.float64(-1.7047785477058888), np.float64(-1.2176989626470633), np.float64(-0.8523892738529444), np.float64(-0.6088494813235317), np.float64(-0.365309688794119), np.float64(-0.12176989626470634), np.float64(0.0), np.float64(0.12176989626470634), np.float64(0.365309688794119), np.float64(0.6088494813235317), np.float64(0.8523892738529444), np.float64(1.2176989626470633), np.float64(1.7047785477058888), np.float64(2.4353979252941267), inf]\n",
            "quant center: [-2.92247757 -1.94831838 -1.46123879 -0.97415919 -0.73061939 -0.4870796\n",
            " -0.2435398   0.          0.          0.2435398   0.4870796   0.73061939\n",
            "  0.97415919  1.46123879  1.94831838  2.92247757]\n",
            "q values: [-inf, np.float64(-2.435397975294127), np.float64(-1.7047785827058888), np.float64(-1.2176989876470634), np.float64(-0.8523892913529444), np.float64(-0.6088494938235317), np.float64(-0.365309696294119), np.float64(-0.12176989876470634), np.float64(0.0), np.float64(0.12176989876470634), np.float64(0.365309696294119), np.float64(0.6088494938235317), np.float64(0.8523892913529444), np.float64(1.2176989876470634), np.float64(1.7047785827058888), np.float64(2.435397975294127), inf]\n",
            "Optimal scaling parameter (a): 0.48707958505882537\n",
            "Minimum MSE: 0.012684904138727481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gphg3lz3bg6K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import hadamard\n",
        "\n",
        "def hadamard_transform_cpu(x):\n",
        "    \"\"\"\n",
        "    纯 CPU 实现 Hadamard 变换（仅支持 2 的幂次维度）\n",
        "    x: 形状为 [..., n] 的张量，n 必须是 2 的幂\n",
        "    \"\"\"\n",
        "    n = x.shape[-1]\n",
        "    assert (n & (n - 1)) == 0, f\"维度 {n} 不是 2 的幂，Hadamard 矩阵仅支持 2^k 维度\"\n",
        "\n",
        "    H = hadamard(n, dtype=np.float32) / np.sqrt(n)  # 归一化\n",
        "    return x @ H.T"
      ],
      "metadata": {
        "id": "LHnJY22IcNzI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "WPts7w_RctWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca35a54a",
        "outputId": "eea65e82-54a1-4b33-a180-7454c50f9145"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.random.rand(32, 64)\n",
        "print(\"矩阵 X 的形状:\", X.shape)\n",
        "xhat = hadamard_transform_cpu(X)\n",
        "print(\"变换后的矩阵 xhat 的形状:\", xhat.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "矩阵 X 的形状: (32, 64)\n",
            "变换后的矩阵 xhat 的形状: (32, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5de2ed44",
        "outputId": "38e55a0a-1a6f-46d7-d926-fc6a88546257"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "X = np.random.rand(32, 64)\n",
        "print(\"矩阵 X 的形状:\", X.shape)\n",
        "xhat = hadamard_transform_cpu(X)\n",
        "print(\"变换后的矩阵 xhat 的形状:\", xhat.shape)\n",
        "# Convert numpy array xhat to torch.Tensor\n",
        "x_had_torch = torch.from_numpy(xhat)\n",
        "\n",
        "# Perform the calculation\n",
        "std = torch.sqrt(torch.mean(x_had_torch**2, dim=-1, keepdim=True)) + 1e-8\n",
        "\n",
        "print(\"x_had_torch 的形状:\", x_had_torch.shape)\n",
        "\n",
        "OPTIMAL_GAUSSIAN_SCALES = {\n",
        "    1: 0.7978845587140913,\n",
        "    1.585: 1.2240089519030855,\n",
        "    2: 1.4935346200015913,\n",
        "    3: 2.051068354131873,\n",
        "    4: 2.513930578568423,\n",
        "    5: 2.9160938834961225,\n",
        "    6: 3.276597282593217,\n",
        "    7: 3.6010497188221655,\n",
        "    8: 3.884938678807525,\n",
        "}\n",
        "\n",
        "scale = OPTIMAL_GAUSSIAN_SCALES[4] * std\n",
        "n_levels = 2 ** 4\n",
        "step = 2 * scale / (n_levels - 1)\n",
        "x_clip = torch.clamp(x_had_torch, -scale, scale)\n",
        "xq = torch.round((x_clip + scale) / step)\n",
        "xq_dequant = xq * step - scale\n",
        "print(f\"original xhat: {xhat}\")\n",
        "print(f\"xq dequant: {xq_dequant}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "矩阵 X 的形状: (32, 64)\n",
            "变换后的矩阵 xhat 的形状: (32, 64)\n",
            "x_had_torch 的形状: torch.Size([32, 64])\n",
            "original xhat: [[ 3.86878332  0.18963859 -0.07150455 ... -0.2114696  -0.04286694\n",
            "   0.10988797]\n",
            " [ 4.00476104 -0.15742877 -0.41666549 ... -0.17256879  0.12637896\n",
            "   0.05964679]\n",
            " [ 4.5204274   0.08438341 -0.21845222 ...  0.19240287  0.27501169\n",
            "  -0.27515666]\n",
            " ...\n",
            " [ 4.29916205  0.15445018 -0.91097936 ...  0.01469263 -0.09612832\n",
            "   0.16471343]\n",
            " [ 4.25988561  0.28805873  0.18535192 ...  0.29734724  0.13099063\n",
            "  -0.31029949]\n",
            " [ 4.15420156 -0.26030808 -0.1824393  ...  0.1875418   0.08439724\n",
            "   0.01126734]]\n",
            "xq dequant: tensor([[ 1.4121,  0.2824, -0.0941,  ..., -0.2824, -0.0941,  0.0941],\n",
            "        [ 1.4439, -0.0963, -0.4813,  ..., -0.0963,  0.0963,  0.0963],\n",
            "        [ 1.5949,  0.1063, -0.3190,  ...,  0.1063,  0.3190, -0.3190],\n",
            "        ...,\n",
            "        [ 1.5430,  0.1029, -0.9258,  ...,  0.1029, -0.1029,  0.1029],\n",
            "        [ 1.5289,  0.3058,  0.1019,  ...,  0.3058,  0.1019, -0.3058],\n",
            "        [ 1.5109, -0.3022, -0.1007,  ...,  0.1007,  0.1007,  0.1007]],\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1849754a",
        "outputId": "064a03d1-2277-403d-b2d2-5db02253ed2a"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Ensure X is a torch tensor for comparison with xq_dequant\n",
        "X_torch = torch.from_numpy(xhat)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = torch.mean((X_torch - xq_dequant)**2)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = torch.mean(torch.abs(X_torch - xq_dequant))\n",
        "\n",
        "print(f\"MSE 误差: {mse.item()}\")\n",
        "print(f\"MAE 误差: {mae.item()}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE 误差: 0.10371601384252502\n",
            "MAE 误差: 0.08587475992192264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJNaoeJibg6K"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from fast_hadamard_transform import hadamard_transform\n",
        "\n",
        "from models.quantization.base_linear import OPTIMAL_GAUSSIAN_SCALES, HadamardTrustQuantizer, HalfHadamardTrustQuantizer\n",
        "\n",
        "\n",
        "def quantize_pack_hadamard_dense(x: torch.Tensor, quantizer: HadamardTrustQuantizer):\n",
        "    assert quantizer.centered\n",
        "    x_had = hadamard_transform(x.reshape(-1, 128), scale=2 ** (-7/2)).reshape(x.shape)\n",
        "\n",
        "    std = torch.sqrt(torch.mean(x_had**2, dim=-1, keepdim=True)) + 1e-8\n",
        "    scale = OPTIMAL_GAUSSIAN_SCALES[quantizer.bits] * std\n",
        "\n",
        "    step = 2 * scale / (quantizer.n_levels - 1)\n",
        "    x_clip = torch.clamp(x_had, -scale, scale)\n",
        "    xq = torch.round((x_clip + scale) / step)\n",
        "\n",
        "    assert xq.min() >= 0 and xq.max() < quantizer.n_levels\n",
        "    return xq, scale, step\n",
        "    # ^ note: xq is in rotated space!\n",
        "\n",
        "def dequantize_dense(xq, scale, step):\n",
        "    return xq * step - scale\n",
        "\n",
        "weight = torch.rand(2, 128).cuda()\n",
        "quantizer = HadamardTrustQuantizer(bits=4)\n",
        "ref = quantizer(weight)\n",
        "xq, scale, step = quantize_pack_hadamard_dense(weight, quantizer)\n",
        "deq = dequantize_dense(xq, scale, step)\n",
        "\n",
        "torch.testing.assert_close(hadamard_transform(ref.reshape(-1, 128), scale=2 ** (-7/2)).reshape(ref.shape), deq, rtol=1e-3, atol=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gcz8EPu8bg6K"
      },
      "outputs": [],
      "source": [
        "from models.quantization.base_linear import QuantizedLinear\n",
        "\n",
        "class Linear4bit(nn.Module):\n",
        "    def __init__(self, quantizer_linear):\n",
        "        super().__init__()\n",
        "\n",
        "        assert isinstance(quantizer_linear.weight_quantizer, HadamardTrustQuantizer)\n",
        "        assert isinstance(quantizer_linear.activation_quantizer, HadamardTrustQuantizer)\n",
        "\n",
        "        self.activation_quantizer = quantizer_linear.activation_quantizer\n",
        "\n",
        "        wq = dequantize_dense(*quantize_pack_hadamard_dense(quantizer_linear.weight, quantizer_linear.weight_quantizer))\n",
        "        self.register_buffer(\"wq\", wq)\n",
        "        self.bias = quantizer_linear.bias\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = dequantize_dense(*quantize_pack_hadamard_dense(x, self.activation_quantizer))\n",
        "        return F.linear(x, self.wq, self.bias)\n",
        "\n",
        "\n",
        "def replace_linears(model):\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, QuantizedLinear):\n",
        "            model._modules[name] = Linear4bit(module)\n",
        "        else:\n",
        "            replace_linears(module)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO6N9xe7bg6L",
        "outputId": "067d8411-f5bd-4636-b7a1-b696e4980053"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1825354/3018025945.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(f\"{PATH}/main.pt\"))\n"
          ]
        }
      ],
      "source": [
        "class PseudoDdp(nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self._orig_mod = nn.ModuleDict({\n",
        "            \"module\": model,\n",
        "        })\n",
        "\n",
        "class PseudoLoader:\n",
        "    def load_state_dict(self, *args, **kwargs):\n",
        "        pass\n",
        "\n",
        "model = PseudoDdp(get_model(DotDict(config['args'])))\n",
        "model.load_state_dict(torch.load(f\"{PATH}/main.pt\"))\n",
        "model = model.cuda()\n",
        "model = model._orig_mod[\"module\"]\n",
        "model = replace_linears(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP3TRYU6bg6L"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toYDl-Krbg6L",
        "outputId": "84848c90-377e-486b-b838-456055b67e3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi! Sign in to let us know how The Coffee House was?\n",
            "by jennifer1\n"
          ]
        }
      ],
      "source": [
        "def generate_text_greedily(model, tokenizer, prompt, max_length=50, device='cuda'):\n",
        "    model.eval()\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, get_logits=True)\n",
        "            logits = outputs['logits'][:, -1, :]\n",
        "\n",
        "        next_token_id = torch.argmax(logits, dim=-1).unsqueeze(-1)\n",
        "        input_ids = torch.cat([input_ids, next_token_id], dim=-1)\n",
        "\n",
        "    return tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
        "\n",
        "generated_text = generate_text_greedily(model, tokenizer, \"Hi!\", max_length=20)\n",
        "print(generated_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fQ-gbM1bg6L",
        "outputId": "497e539e-ea4d-4fc9-93c7-dbcf22413b6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "822.083584\n"
          ]
        }
      ],
      "source": [
        "numel = 0\n",
        "for name, param in model.named_buffers():\n",
        "    numel += param.numel()\n",
        "    # print(name, param.numel())\n",
        "\n",
        "print(numel/1e6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR0IymV-bg6L"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "transformers",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}